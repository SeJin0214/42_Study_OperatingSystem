# 멀티프로세서 스케줄링

병행성을 어느 정도 안 뒤에 다루는 게 좋다.

> 멀티코어 덕분에 멀티프로세서 시스템이 일반적이게 되었다.
> 

문제점

- CPU 코어가 많은데도 불구하고 대부분의 프로그램이 코어 하나만 사용한다.

해결방안

- 응용 프로그램을 병렬(parallel)로 실행되도록 다시 작성해야 한다.
- 쓰레드를 이용한다.

## 배경 : 멀티 프로세서 구조

> **멀티프로세서 스케줄링에 대한 새로운 문제점을 이해하기 위해서**는 단일 CPU 하드웨어와 멀티 CPU 하드웨어의 **근본적인 차이에 대한 이해가 필요**
> 

- 다수의 프로세서 간의 데이터 공유, 하드웨어 캐시 사용 방식에서 근본적인 차이가 발생한다.

- **캐시 지역성**
    - 시간적 지역성
        - 한 번 접근했던 데이터는 가까운 미래에 다시 접근할 가능성이 높다.
        - ex) 반복문으로 같은 변수 접근하기
    - 공간적 지역성
        - 접근했던 데이터 주변의 데이터에 접근할 가능성이 높다
        - ex) 배열 접근하기

단일 프로세서는 캐시가 잘 작동하나 아래와 같은 멀티 프로세서는 어떻게 사용할 것인가?

![Untitled](image\multi_processor_cache.png)

- 캐시 일관성 문제(cache coherence)
    
    > 레이스 컨디션과 비슷한 문제
    > 
    > 
    > **CPU 1에서** 실행 중인 프로그램이 주소 A를 (**D 값을) 읽는다**고 가정하자.
    > 데이터가 CPU 1 캐시에 존재하지 않기 때문에 시스템은 **메인 메모리로부터 데이터를 가져오고 값 D를 얻는다**. 그런 후 프로그램은 주소 A의 값을 변경한다. 변경은 **캐시에 존재하는 값만 D′ 으로 갱신**한다. 메모리에 데이터를 쓰는 것은 시간이 오래 걸리므로 **메인 메모리에 기록하는 것은 보통 나중에 한다**. 
    > 
    > 운영체제가 프로그램의 실행을 중단하고 **CPU 2로 이동**하기로 결정한다고 가정하자. 프로그램은 주소 A의 값을 다시 읽는다.
    > CPU 2의 캐시에는 그러한 데이터가 존재하지 않고 따라서 **시스템은 메인 메모리에서 데이터를 가져온다**. 이때 **D′ 이 아니라 옛날 값인 D를 가져온**다
    > 
    - 기본적으로 하드웨어가 해결책을 제공한다.
    - 메모리 주소를 계속 감시하고 올바른 상황일 때만 발생하도록 시스템을 관리한다.
    - 여러 개의 프로세스들이 하나의 메모리에 갱신할 때에는 항상 공유되도록 한다.
    - 버스 스누핑(bus snooping) 이라는 오래된 기법을 사용한다. (이것과 관련된 유닛이 있을 것이다.)
        - 캐시와 메모리를 연결하는 버스의 통신 상황을 계속 모니터링한다.
        - 어느 프로세서에서 캐시 데이터에 대한 변경이 발생하면, 복사본을 무효화 하거나 갱신한다.

내가 접근하려는 데이터가 다른 CPU 캐시에 있을 수도 있다. 

### 동기화 관련

올바른 연산 결과를 위해 락과 같은 상호 배제를 보장하는 동기화 기법이 많이 사용된다.

구조체를 원자적으로 갱신하기 위해서는 락이 필요하다.

ex) pthread_mutex_t 

락을 하는 동안 다른 CPU는 접근할 수 없다.

> 성능 측면에서 문제가 있다. CPU의 개수가 증가할수록 동기화된 자료 구조에 접근하는 연산은 매우 느리게 된다.
> 

### 캐시 친화성

**프로세스가 매번 다른 CPU에서 실행되면** 실행할 때마다 **필요한 정보를 캐시에 다시 탑재해야만 하기 때문**에 프로세스의 성능은 더 나빠질 것

하드웨어의 캐시 일관성 프로토콜 덕분에 다른 CPU에서 실행되더라도 프로그램을 제대로 실행된다. 

> 멀티프로세서 스케줄러는 스케줄링 결정을 내릴 때 캐시 친화성을 고려해야 한다
> 

<aside>
💡 그래서 멀티 프로세서 시스템 스케줄러 개발은 어떻게 하는가?

</aside>

## 방법

### 단일 큐 스케줄링(single queue multiprocessor scheduling : SQMS)

단일 프로세서 스케줄링의 기본 프레임워크를 그대로 사용 하는 것

CPU (여러 개) : 스케줄링 큐 (1개)

- 장점
    - 단순함, 다수 CPU에서 동작하도록 하는 데 많은 변경이 필요하지 않음
- 단점
    - 확장성이 부족함
        - 다수의 CPU를 작동하기 위해 코드에 일정 형태의 락을 삽입하는데, 이 때문에 성능 저하가 발생한다.
        - CPU의 개수가 증가할수록 더욱 그렇다.
    - 캐시 친화성이 부족
        
        ![Untitled](image\much_overhead.png)
        
        - 이러면 성능이 좋지 않아… 캐시를 매번 업데이트 해야 한다. (오버헤드 증가)
            
            ![Untitled](image\little_overhead.png)
            
        - 실행 했던 프로세스를 또 실행한다면 기존에 있던 캐시를 계속 사용할 수 있어서 좋다!
    - 이렇게 하려면 구현이 매우 복잡질 수 있다.

### 멀티 큐 스케줄링(multi-queue multiprocessor scheduling : MQMS)

CPU마다 큐를 하나씩 둔 방식

1.  작업이 시스템에 들어가면 하나의 스케줄링 큐에 배치된다
2. 배치될 큐의 결정은 적당한 방법을 따른다 ex) 랜덤, 작업이 적은 큐로

- 장점
    - 확장성이 좋음
    - 락과 캐시 경합은 문제가 되지 않음
    - 캐시 친화적이다.
- 단점
    - 워크로드의 불균형
        
        ![Untitled](image\workload.png)
        
        - 이랬을 때
            
            ![Untitled](image\cpu_monopoly.png)
            
        - A가 CPU 하나를 독점
        - 더군다나 더 큰 문제는?
            
            ![Untitled](image\empty_workload.png)
            
        - A가 종료된 상황
            
            ![Untitled](image\idle_cpu.png)
            
        - CPU 하나가 idle 상태로 빠져 놀게 된다.

<aside>
💡 해결방안

이주(migration)

작업을 다른 CPU로 이동하는 것! (지속적으로 이주시킨다)

![Untitled](image\migration.png)

</aside>

많은 방법 등이 존재하는데 기본적인 한 가지는 작업 훔치기(work stealing)이라는 기술이다.

작업의 개수가 낮은 큐가 다른 큐들의 작업의 개수를 확인하여 비교했을 때 더 많다면 작업을 갖고오는 형태다.

이것도 자주 하게 되면 오버헤드, 확장성 문제가 생기니 적절하게 사용하게 해야 하나

### 리눅스 멀티 프로세서 스케줄러

3가지 스케줄러 존재

1.  O(1) 스케줄러
    1. 멀티 큐
    2. 우선순위 기반
2. Completely Fair Scheduler(CFS)
    1. 멀티 큐
    2. 결정론적, 비례배분 방식(보폭 스케줄링에 가까움)
3. BF 스케줄러 (BFS)
    1. 단일 큐
    2. 비례 배분 방식

자세한 건 논문 참조

### 요약

단일 큐 방식(SQMS)는 구현이 단순하나, 확장성이 좋지 못하고 캐시 친화성이 떨어진다.

멀티 큐 방식은 확장성이 좋고 캐시 친화성이 좋으나, 워크로드의 불균형 문제가 있고 구현도 복잡하다.

만들기 어려우니, 돈을 많이 주거나, 너가 잘한다면 만들어라 

### 좀 더 찾아볼 것

캐시 일관성 프로토콜