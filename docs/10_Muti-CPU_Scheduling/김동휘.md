# 멀티프로세서 스케줄링 (고급)
멀티 프로세스 스케줄링(multiprocessor scheduling)은 어렵기 때문에 병행성(concurrency)를 어느정도 깊게 공부하고 다루는게 좋은 챕터이다.  
</br>
</br>
싱글 코어 CPU의 성능 개선이 한계에 봉착한 후, 여러 개의 CPU코어가 하나의 칩에 내장된 멀티 코어(multicore)프로세서로 인해 멀티 프로세서(multiprocessor)가 대중화 되었다.  

다중 CPU 시대가 오면서 많은 문제가 발생하였다. 전통적 응용프로그램은 CPU를 하나만 사용하기에 많은 CPU가 추가돼도 빨라지지 않는다.  
해결을 위해서는 병렬실행으로 응용프로그램을 재작성해야한다. 이를 위해서는 쓰레드를 이용한다. (쓰레드는 나중에 상세히 배운다)  
멀티 쓰레드 응용프로그램은 작업을 여러 CPU에 할당하기에 CPU가 많아지만 더 빨라진다.  

응용체제 또한 멀티프로세스 스케줄링으로 문제에 직면했다. 지금까지는 단일 프로세서 스케줄링의 원칙들에 대해 배웠던 것이다. 지금까지 배운 것을 여러 CPU에서 동작하도록 확장시켜야 한다.

	"여러 CPU에 작업을 어떻게 스케줄 해야 하는가?"
</br>
</br>


## 1. 배경: 멀티 프로세서 구조

앞서 단일 CPU 하드웨어와 멀티 CPU 하드웨어의 근본적 차이에 대한 이해가 필요하다.  

다수 프로세서간 대에터 공유, 하드웨어 캐시의 사용방식에서 근본적 차이가 발생한다.(여기서는 개념적으로만 다루겠다)
단일 CPU시스템에는 하드웨어 캐시 계층이 존재한다. 이 캐시는 프로그램을 빠르게 실행하기 위해 존재한다.

	* 캐시 : 매인메모리에서 자주 사용되는 데이터 복사본을 저장하는 작고 빠른 메모리

메인메모리는 모든 데이터를 저장하나 느리다. 자주 접근하는 데이터를 캐시에 임시로 저장하며 시스템은 크고 느린 메모리를 빠른 것 처럼 보이게 한다.  

캐시는 지역성(locality)에 기반한다.  
지역성에는 시간지역성(temporal locality)과 공간지역성(spatial locality)가 있다.  

### 시간 지역성 
	: 데이터가 한 번 접근되면 가까운 미래에 다시 접근되기 쉬움. 
	ex_루프에서 여러 번 반복해서 접근되는 변수 또는 명령어 자체
### 공간 지역성 
	: 프로그램이 특정 주소의 데이터를 접근하면 그 주소 주변 데이터가 접근되기 쉬움.

그렇다면,  
하나의 시스템에 여러 프로세서가 존재하며 하나의 공유 메모리가 있다면?  
멀티프로세서 시스템에서 캐시를 사용하는 것은 훨씬 복잡하다.

### 캐시 일관성 문제(cache coherence)
여러 CPU를 전환하면서 캐시에 저장된 값을 활용할 수 없어지거나, 갱신되지 않은 값을 참조하게 되는 등의 문제

	#### 해결책 
	: 하드웨어에 의해 메모리 주소를 계속 감시하고 항상 제대로 된 상황만 	발생하도록 시스템을 관리한다. 특히 여러 개의 프로세스들이 하나의 메모리에 갱신할 때 항상 공유되도록 한다. 버스 기반 시스템에서는 버스 스누핑(bus snooping)이라는 기법을 사용한다. 캐시는 자신의 메모리를 연결하는 버스의 통신상황을 계속 모니터링한다. 캐시 데이터에 대한 변경이 발생하면 자신의 복사본을 무요화(invalidate)시키거나 갱신한다. 

</br>
</br>

## 2. 동기화를 잊지 않기
일관성 유지에 대해 캐시가 담당한다고 해서 프로그램 또는 운영체제가 공유데이터 접근시 겅정할 필요가 없지 않다. 이는 병행성에 관한 문제이며 추후 배울 부분이다.  

CPU들이 동일한 데이터 또는 구조체에 접근할 때 올바른 연산 결과를 보장하기 위해 락과 같은 상호 배제를 보장하는 동기화 기법이 많이 사용된다. (락-프리 데이터 구조 등 복잡하고 특수한 경우는 나중에 배움)  

여러 CPU가 동시에 사용하는 공유 큐가 있을 때, 캐시의 일관성을 보장하는 프로토콜이 존재한다 하더라도 락이 있어야 항목의 추가나 삭제가 제대로 동작할 수 있다.  
 연결리스트에서 원소 하나를 삭제한다고 할 때, 두 CPU의 쓰레드가 동시에 이 루틴으로 진입한다고 가정하면 원래는 각각이 자신만의 스택을 갖고 있고 동일한 헤드 원소를 제거하려고 할 것이다. 그러나 문제가 발생하면 헤드원소를 두 번 삭제하거나 같은 데이터를 두 번 반환하는 등을 야기한다.  
해결책은 락(lock)을 사용하여 올바르게 동작하도록 하는 것인데, 문제는 성능적 측면에 있다.  CPU의 개수가 증가할수록 동기화된 자료 구조에 접근하는 연산이 매우 느려진다.  
</br>
</br>

## 3. 마지막 문제점: 캐시 친화성
캐시 친화성(cache affinity) : CPU에서 실행될 때 프로세스는 해당 CPU캐시와 TLB(translation lookaside buffer; 가상메모리주소를 물리적 주소로 변환하는 속도를 높이기 위해 사용되는 캐시)에 상당한 양의 상태정보를 올려놓기 때문에, 다음번 프로세스가 실행될 때 동일 CPU에서 실행되는 것이 유리하다.  
반면 프로세스가 매번 다른 CPU에서 실행되면 실행마다 필요한 정보를 캐시에 다시 탑재해야 하기에 성능은 더 나빠질 것이다. 가능한 한 프로세스를 동일한 CPU에서 실행하려고 노력하는 방향으로 결정해야 한다.  
</br>
</br>

## 4. 단일 큐 스케줄링
이제 멀티프로세서 시스템의 스케줄러 개발 방법에 대해 논의한다.  

단일 큐 멀티프로세서 스케줄링(single queue multiprocessor scheduling, SQMS)
: 가장 기본적인 방식으로, 단일 프로세서 스케줄링의 기본 프레임워크를 그대로 사용하는 것이다.  
#### 장점
: 단순하다. 기존정책을 다수 CPU에서 동작하도록 하는데는 많은 변경이 필요없다. 
#### 단점
1) 확장성(scalability)의 결여
   -	스케줄러가 다수 CPU에서 제대로 동작하게 하기 위해 코드에 일정 형태의 락을 삽입하며 이는 SQMS 코드가 단일 큐를 접근할 때(실행시킬 작업을 찾을 때)올바른 결과를 유도한다. 그러나 락은 (특히 CPU개수가 증가할수록)성능을 크게 저하시킬 수 있다. 단일 락에 대한 경쟁이 증가할 수록 시간 소모가 커진다.
2) 캐시 친화성
	- 실행할 5개의 작업 (ABCDE)가 있고 4개의 프로세서가 있을 떄 스케줄링 큐는 1자 사슬로 이어져 있을 것이다. 각 CPU에서는 공유 큐에서 다음 작업을 선택하기에 각 작업은 CPU를 옭겨다니게 된다. 캐시 친화성 관점에서 잘못된 선택이다.  
	- 해결을 위해 대부분의 SQMS 스케줄러는 한 프로세스가 같은 CPU에서 재실행될 수 있도록 시도한다. 그러나 이런 방식은 구현이 복잡해질 수 있다.

</br>
</br>

## 5. 멀티 큐 스케줄링
멀티 큐 멀티 프로세서 스케줄링(multi-queue multiprocessor scheduling, MQMS)
: 앞선 문제 해결을 위해 일부 시스템은 멀티 큐, 예를 들어 CPU마다 큐를 하나씩 둔다. 
- 기본 스케줄링 프레임워크는 여러 개의 스케줄링 큐로 구성된다.
- 각 큐는 라운드로빈같은 특정 스케줄링 규칙을 따를 것이고 어떤 스케줄링 기법도 사용가능하다. 
- 작업이 시스템에 들어가면 하나의 스케줄링 큐에 배치된다. 배치될 큐의 결정은 적당한 방법을 따른다. (무작위, 다른 큐보다 작업수가 작은 큐 등)
- 그 후에는 각각 독립적으로 스케줄 되기에, 단일 큐 방섹에서 보았던 정보 공유 및 동기화 문제가 해결된다.

### 장점
- 확장성이 좋다. CPU 개수가 증가할수록 큐의 개수도 증가하무로 락과 캐시 경합은 더이상 문제되지 않는다.
- 본질적으로 캐시 친화적이다. 작업이 같은 CPU에서 진행되므로 캐시 내용을 재사용하는 이점을 가져간다.
### 단점
- 워크로드의 불균형(load imbalance)
  - 4개의 작업, 2개의 cpu를 가정할 때 1개의 cpu가 2개씩 나눠가진다고 하면, 1번 cpu의 하나의 작업이 종료되었을 때 남은 하나의 작업이 cpu를 독점하고 다른 cpu를 2개의 작업이 공유하는 불균형이 일어난다. 만약 남은 하나의 작업마저 종료되면, 1번 cpu는 유휴상태가 되며 다른 cpu만 계속 일한다. 
- 해결방안
  - 작업을 한 CPU에서 다른 CPU로 이주(migration)시키며 워크로드 균형을 달성한다.
  - 이주의 필요여부를 결정하는 방법
    - 작업 훔치기(work stealing) : 작업의 개수가 낮은 큐가 가끔 다른 큐에 훨씬 많은 수의 작업이 있는지 검사하고, 가져온다. 
    - 너무 자주 검사하게 되면 높은 오버헤드로 확장성에 문제가 생기기에 적절한 값을 찾아내야 한다.

</br>
</br>

## Linux 멀티 프로세서 스케줄러

Linux에서는 세가지 스케줄러가 등장했다.
1. O(1) 스케줄러
	- 멀티 큐
	- 우선순위 기반 스케줄러(MLFQ와 유사)
	- 특히 상호작용을 가장 우선시
2. Completely Fair Scheduler(CFS)
	- 멀티 큐
	- 결정론적 비례배분 방식(보폭스케줄링과 유사)
3. BF 스케줄러 (BFS)
	- 단일 큐
	- 비례배분 방식
	- EEVDF라는 더 복잡한 방식에 기반함
