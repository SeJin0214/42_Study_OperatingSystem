# 멀티프로세서 스케줄링 (고급)
멀티코어(multicore) = 여러 개의 cpu 코어가 하나의 칩에 내장.  
다중 cpu의 문제 발생  
* 전통 프로그램은 1개의 cpu사용  
* 많은 cpu를 사용해도 빨리 실행 X   
해결방안 -> 병렬(parallel)실행. 쓰레드 사용.

## 13.1 배경 : 멀티프로세서 구조
단일 cpu 와 멀티 cpu의 차이.  
다수의 프로세서 간에 데이터의 공유, 하드웨어 캐시 사용 방식의 차이.

* 단일 cpu
    * 하드웨어 캐시 계층이 존재.
        * 캐시란? 메인 메모리에서 자주 사용되는 데이터나 최근에 사용된 데이터를 임시로 저장하는 빠른 메모리. 캐시는 데이터 접근 시간을 줄이고, 시스템 성능을 향상시킴. 메인 메모리는 모든 데이터를 저장하지만, 속도가 느림.
        * 캐시 지역성에 기반
            * 시간 지역성이란? 데이터가 한 번 접근되면 가까운 미래 다시 접근이 쉬움.
            * 공간 지역성이란? 프로그램에서 특정 주소의 데이터에 접근하면, 특정 주소 주변의 데이터 접근이 쉬움. ex)배열

멀티 프로세서 시스템에서 캐시 사용할 때 캐시 일관성 문제가 생김.
* 캐시 일관성 문제(Cache Coherency) : 여러 캐시가 동일한 메모리 위치를 동시에 캐시할 때 발생하는 문제.  
* 해결책 : 하드웨어가 메모리 주소를 계속 감시, 제대로된 상황만 발생하게 시스템 관리.
    * 버스 스누핑(bus snooping) : 캐시는 자신과 메모리 연결하는 버스의 통신 상황 모니터링. 캐시 데이터 변경이 발생 시, 자신의 복사본을 무효화시키거나 갱신 시킴.


## 13.2 동기화를 잊지 마시오.
* 공유 데이터 접근 문제는? -> 여러 cpu가 동일 데이터 및 구조체 접근 시, 올바른 연산을 보장하기 위해 락과 같은 상호 배제 보장 동기화 기법 사용함.    
* cpu 동시 사용하는 공유 큐 경우, 캐시 일관성을 보장하더라도, 락이 없는 경우 항목 추가 및 삭제가 제대로 동작하지 않을 수 있음.    
* 락을 사용하여 올바르게 작동하더라도, 성능 측면의 문제 발생(cpu 개수 증가시 동기화된 자료 구조 접근아는 연산이 매우 느려짐.)  

## 13.3 마지막 문제점 : 캐시 친화성
캐시 친화성(cache affinity)  
* cpu 실행 시, 프로세스는 해당 cpu캐시와 TLB에 상태 정보 올림. 다음 번에 프로세스 실행 될 때 동일한 cpu에서 실행되는 것이 유리. 해당 cpu 캐시에 해당 정보 존재하기에 빨리 실행됨. 반대로 다른 cpu가 실행하면 그때마다 정보를 탑재하기에 성능이 나빠짐.

## 13.4 단일 큐 스케줄링
단일 큐 멀티프로세서 스케줄링 : 단일 프로세서 스케줄링의 기본 프레임워크 그대로 사용.  
* 장점
    단순함 - 기존 정책을 다수 cpu에서 동작하도록 많은 변경이 필요하지 않음.
* 단점
    1. 확장성 결여
        * 스케줄라가 다수 cpu 제대로 동작하기 위해 코드에 락을 삽입. 락은 코드가 단일 큐 접근 시. 올바른 결과 나오게 하지만, 성능을 크게 저하 시킬 수 있으며, cpu의 개수가 증가 할수록 더 늦어짐.
    2. 캐시 친화성 
        ![Untitled](image\SQMS_01.png)
        시간 흐름에 따라 작업은 주어진 타임 슬라이스 동안 실행.
        ![Untitled](image\SQMS_02.png)
        각 cpu는 공유 큐에서 다음 작업을 선택함, 각 작업은 cpu 옮겨 다님.
        SQMS 스케줄러는 프로세스가 동일한 cpu에서 재실행 될 수 있도록 시도해줌.  
        캐시 친화성을 고려해 스케줄링, 오버헤드 균등하게 하기 위해 여러 군대로 분산시키는 정책 사용.
        ![Untitled](image\SQMS_03.png)
        A부터 D까지의 작업을 각각의 프로세서에서 실행. E만 하나의 프로세서에서 다른 프로세서로 이동하여 대부분의 작업에게 친화성 보존.

## 13.5 멀티 큐 스케줄링
멀티 큐 멀티프로세스 스케줄링 : 단일 큐 스케줄링 문제 때문에 일부 시스템은 멀티 큐, cpu마다 큐를 하나씩 둠.  
* 여러 개의 스케줄링 큐로 구성.
* 각 큐는 라운드 로빈 같은 특정 스케줄링 규칙을 따름.
* 작업이 시스템에 들어가면 하나의 스케줄링 큐에 배치
* 배치될 큐의 결정은 적당한 방법 따름.
* 각각 독립적으로 스케줄 되기에 단일 큐 방식에서의 정보의 공유 및 동기화 문제 피함.

![Untitled](image\MQMS_01.png)
A, B, C, D 네 개의 작업이 시스템이 존재. cpu 각자 하나씩의 스케줄링 큐 갖음.  
큐 스케줄링 정책에 따라 각 cpu 2개씩 작업을 갖음.  
![Untitled](image\MQMS_02.png)
라운드 로빈 경우의 스케줄링.

* 이점
  * MQMS가 SQMS 비해 확장성이 좋음.  
  * cpu개수 증가할수록, 큐의 개수 증가하여 락과 캐시 경합 문제 없음.
  * MQMS 캐시 친화적. 작업이 같은 cpu에서만 실행되어, 캐시 재사용 이점.

* 문제
  * 워크로드의 불균형
  * ![Untitled](image\MQMS_03.png)
  * A, B, C, D 중 C가 먼저 종료된 경우, 해당 스케줄링.
  * ![Untitled](image\MQMS_04.png)
  * 라운드 로빈 정책 스케줄링. A가 B, D 보다 2배의 cpu 차지.
  * ![Untitled](image\MQMS_05.png)
  * A도 종료 되었을 때의 스케줄링.
  * ![Untitled](image\MQMS_06.png)
  * 라운드 로빈 정책 스케줄링. 오버헤드 불균형 문제 발생.
  * 이주(migration / 작업을 다른 cpu로 이주)로 워크로드 균형 달성
  * 이주의 경우 한 번으로 문제가 해결이 되지 않음. 작업을 지속적으로 이주시켜야함.
  * 그외 다른 이주 패턴들이 있음.
  * 이주의 필요 여부는 어떻게 결정? -> 작업 훔치기.
  * 작업 훔치기란? 작업 개수가 낮은 큐가 다른 큐의 작업 수를 검사, 다른 큐에 작업이 더 차있다면 하나 이상의 작업을 가져옴.

## 13.6 Linux 멀티프로세서 스케줄러
* O(1) 스케줄러 : 멀티큐, 우선 순위스케줄러로 프로세서의 우선순위를 시간에 따라 변경하여 우선순위가 가장 높은 작업 선택, 상호 작용 우선시 
* Completely Fair Scheduler(CFS) : 멀티큐, 결정론적 비례배분방식
* BF스케줄러 : 단일큐, 비례배분 방식 사용.

## 13.7 요약
* 단일 큐 방식 : 구현이 용이, 워크로드 균형을 맞추기에 용이. 많은 개수의 프로세스에 대해 확정성과 캐시 친화성이 좋지 않음.  
* 멀티 큐 방식 : 확장성이 좋고 캐시 친화성을 잘 처리, 워크로드 불균형 문제, 구현이 복잡. 